{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day9_BoW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5RS8+c/suzFBXDSKLFHG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psbhargava/100daysofnlp/blob/master/Day9_BoW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKn2GKGx8rL",
        "colab_type": "text"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4LrsD9rH1S2",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://cdn-media-1.freecodecamp.org/images/qRGh8boBcLLQfBvDnWTXKxZIEAk5LNfNABHF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEmEur2sD0Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGxUqmUdHbP_",
        "colab_type": "text"
      },
      "source": [
        "Tokenize each the sentences, example\n",
        "Input : \"John likes to watch movies. Mary likes movies too\"\n",
        "Ouput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7d87FmJHT3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentences):\n",
        "    words = []\n",
        "    for sentence in sentences:\n",
        "        w = word_extraction(sentence)\n",
        "        words.extend(w)\n",
        "        \n",
        "    words = sorted(list(set(words)))\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq5_R1dWHYT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_extraction(sentence):\n",
        "    ignore = ['a', \"the\", \"is\"]\n",
        "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
        "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
        "    return cleaned_text "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy7bgHomHgCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_bow(allsentences):    \n",
        "    vocab = tokenize(allsentences)\n",
        "    print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
        "\n",
        "    for sentence in allsentences:\n",
        "        words = word_extraction(sentence)\n",
        "        bag_vector = numpy.zeros(len(vocab))\n",
        "        for w in words:\n",
        "            for i,word in enumerate(vocab):\n",
        "                if word == w: \n",
        "                    bag_vector[i] += 1\n",
        "                    \n",
        "        print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SWREfzTHih1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\", \n",
        "            \"I looked for Mary and Samantha at the bus station\", \n",
        "            \"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pD1gISFHk4O",
        "colab_type": "code",
        "outputId": "a6d6f1b3-c245-4b3a-93fa-27f3ee28c52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "generate_bow(allsentences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word List for Document \n",
            "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'the', 'took', 'train', 'until', 'waited', 'was'] \n",
            "\n",
            "Joe waited for the train \n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "\n",
            "The train was late \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
            "\n",
            "Mary and Samantha took the bus \n",
            "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            "\n",
            "I looked for Mary and Samantha at the bus station \n",
            "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Mary and Samantha arrived at the bus station early but waited until noon for the bus \n",
            "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O1SL_tGIaZf",
        "colab_type": "text"
      },
      "source": [
        "## Limitations of BOW\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9cYqPqVIhZE",
        "colab_type": "text"
      },
      "source": [
        "Semantic meaning: the basic BOW approach does not consider the meaning of the word in the document. It completely ignores the context in which itâ€™s used. The same word can be used in multiple places based on the context or nearby words.\n",
        "    \n",
        "Vector size: For a large document, the vector size can be huge resulting in a lot of computation and time. You may need to ignore words based on relevance to your use case."
      ]
    }
  ]
}